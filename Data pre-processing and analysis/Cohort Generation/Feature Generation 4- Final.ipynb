{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generates additional condition history covariates using concept ancestors for following condition categories\n",
    "\n",
    "Arthritis\n",
    "\n",
    "Autoimmune\n",
    "\n",
    "Cancer\n",
    "\n",
    "Chronic Kidney\n",
    "\n",
    "Diabetes Mellitus\n",
    "\n",
    "HIV\n",
    "\n",
    "Hypertension\n",
    "\n",
    "Menopause\n",
    "\n",
    "Thyroid Disorder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential refactoring change could be to merge covariate generation 1 and generation 2\n",
    "in_name = \"manuscript_covariates_2_final\"\n",
    "out_name = \"manuscript_covariates_3_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import sparse\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "sys.path.append(\"..\")\n",
    "import Utils.dbutils as dbutils\n",
    "import Utils.data_utils as data_utils\n",
    "import Generators.CohortGenerator as CohortGenerator\n",
    "import Generators.FeatureGenerator as FeatureGenerator\n",
    "import config\n",
    "local_imports = (\n",
    "    dbutils,\n",
    "    data_utils,\n",
    "    CohortGenerator,\n",
    "    FeatureGenerator,\n",
    "    config\n",
    ")\n",
    "for i in local_imports:\n",
    "    i = importlib.reload(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Name Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## database connection parameters\n",
    "# username = config.PG_USERNAME #we use peer authentication so don't need use vars, but in theory would pass them into config_path\n",
    "# password = config.PG_PASSWORD\n",
    "database_name = config.DB_NAME\n",
    "print(database_name)\n",
    "config_path = 'postgresql://{database_name}'.format(\n",
    "    database_name = database_name\n",
    ")\n",
    "connect_args = {\"host\": '/var/run/postgresql/'} # connect_args to pass to sqlalchemy create_engine function\n",
    "\n",
    "# schemas \n",
    "schema_name = 'eol_test_ncjones' # all created tables will be created using this schema\n",
    "cdm_schema_name = config.OMOP_CDM_SCHEMA # the name of the schema housing your OMOP CDM tables\n",
    "print(f\"cdm schema: {cdm_schema_name}\")\n",
    "# caching\n",
    "reset_schema = False # if true, rebuild all data from scratch\n",
    "\n",
    "# set up database, reset schemas as needed\n",
    "db = dbutils.Database(config_path, schema_name, connect_args, cdm_schema_name)\n",
    "# if reset_schema:\n",
    "#     db.execute(\n",
    "#         'drop schema if exists {} cascade'.format(schema_name)\n",
    "#     )\n",
    "# db.execute(\n",
    "#     'create schema if not exists {}'.format(schema_name)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Below is stuff to query adverse events\n",
    "\n",
    "\n",
    "# This is to generate adverse condition events based on condition names\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        c.concept_name as concept_name,\n",
    "        c.concept_id as concept_id,\n",
    "        c.domain_id as domain_id\n",
    "    from\n",
    "        {omop_schema}.concept c\n",
    "    where \n",
    "        c.domain_id = 'Condition' \n",
    "\"\"\".format(\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA,\n",
    ")\n",
    "diagnosis_names = db.query(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##### Below is stuff to query adverse events\n",
    "\n",
    "\n",
    "# This is to generate adverse condition events based on condition names\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        c.concept_name as concept_name,\n",
    "        c.concept_id as concept_id,\n",
    "        c.domain_id as domain_id,\n",
    "        ca.ancestor_concept_id as ancestor_concept_id,\n",
    "        ca.descendant_concept_id as descendant_concept_id\n",
    "    from\n",
    "        {omop_schema}.concept c\n",
    "    join {omop_schema}.concept_ancestor ca on c.concept_id = ca.descendant_concept_id\n",
    "    where\n",
    "       c.domain_id = 'Condition'\n",
    "\"\"\".format(\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA,\n",
    ")\n",
    "diagnosis_names_ca = db.query(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_cond_ca = {\"Arthritis\" : \n",
    "                     ([\"arthritis\"],\n",
    "                     [4291025, 79109, 4117097, 4262590, 4167984, 80482, 80809]),\n",
    "                 \"Autoimmune\" : \n",
    "                     ([\"sj√∂gren\",  \"rheumatoid_arthritis\", \"reactive_arthritis\", \"lupus_erythematosus\", \"dermatomyositis\"],\n",
    "                     [4182582, 4224624, 434621, 4318558, 4215792, 4051056, 4034815]),\n",
    "                 \"Cancer\" : \n",
    "                     ([\"cancer\",\"carcinoma\",\"malignan\",\"leukemia\",\"lymphoma\",\"sarcoma\"],\n",
    "                     [443392, 764422, 764225, 45757107, 45773534, 432851, 46270083,40493428,4114222,197506,4153882,40491001,4312698,36716620,4116238,40492037,4154630,4147164]),\n",
    "                 \"Chronic Kidney\" :\n",
    "                     ([\"chronic_kidney\",\"chronic_renal_failure\"],\n",
    "                     [46271022,45763854,44782429,443597,443611,43531578,443601,443612,443614,198185, 443961, 4322556, 4128067, 193782]),\n",
    "                 \"Diabetes Mellitus\" : \n",
    "                     ([\"diabetes_mellitus\"],\n",
    "                     [201820, 4019513, 4024659, 36713275, 4212631]),\n",
    "                 \"Thyroid Disorder\" : \n",
    "                     ([\"hashimoto_thyroiditis\", \"graves\"],\n",
    "                     [135215, 4130018, 4100629,4232076]),\n",
    "                 \"HIV\" :\n",
    "                     ([\"hiv\"],\n",
    "                     [4013106,4235563,36714516,4171125]),\n",
    "                 \"Hypertension\":\n",
    "                     ([\"hypertension\"],\n",
    "                     [316866, 37208172, 42709887, 4227517, 45768449, 43020424]),\n",
    "                 \"Menopause\":\n",
    "                     ([\"menopause\"],\n",
    "                     [4128329])\n",
    "                }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting names of the concept ancestors (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to get concept names from a specified table\n",
    "def get_concept_names(concept_ids):\n",
    "    concept_names = []\n",
    "    for idx in concept_ids:\n",
    "        # Replace this line with your table code\n",
    "        concept_name = diagnosis_names_ca.loc[diagnosis_names_ca['descendant_concept_id'] == idx, 'concept_name'].iloc[0]\n",
    "        concept_names.append(concept_name)\n",
    "    return concept_names\n",
    "\n",
    "# Create a Pandas Excel writer to save the output\n",
    "with pd.ExcelWriter('category_concept_ancestors.xlsx') as writer:\n",
    "    # Iterate through the dictionary\n",
    "    for category in category_to_cond_ca:\n",
    "        # Get the list of condition concept ids and names\n",
    "        condition_concept_ids = category_to_cond_ca[category][1]\n",
    "        condition_concept_names = get_concept_names(condition_concept_ids)\n",
    "\n",
    "        # Create a DataFrame with the required columns\n",
    "        dataframe = pd.DataFrame({\n",
    "            'concept_ancestor_condition_id': condition_concept_ids,\n",
    "            'concept_ancestor_name': condition_concept_names\n",
    "        })\n",
    "\n",
    "        # Write the DataFrame to an Excel sheet\n",
    "        dataframe.to_excel(writer, sheet_name=category, index=False)\n",
    "\n",
    "print(\"Excel file created with sheets for each condition category.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving concept ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_condition_ids = []\n",
    "condition_name_map = dict()\n",
    "condition_id_name_map = dict()\n",
    "condition_id_fullname_map = dict()\n",
    "pn_to_id_map = dict()\n",
    "condition_name_hits = []\n",
    "condition_ids = []\n",
    "# Obesity, Morbid obesity\n",
    "# condition_name_hits.append([\"morbid\", \"obesity\"])\n",
    "# # Malignancies/cancer\n",
    "condition_name_hits.append(\"cancer\")\n",
    "\n",
    "condition_name_hits.append(\"malignan\")\n",
    "\n",
    "\n",
    "# # HIV\n",
    "condition_name_hits.append(\"hiv\")\n",
    "# # Chronic Kidney disease stage 4 or 5\n",
    "condition_name_hits.append([\"chronic\", \"kidney\"])\n",
    "# # Hemodialysis \n",
    "\n",
    "# # Diabetes mellitus (with or without any complication)\n",
    "condition_name_hits.append([\"diabetes\", \"mellitus\"])\n",
    "\n",
    "# # Menopause\n",
    "condition_name_hits.append(\"menopause\")\n",
    "\n",
    "condition_name_hits.append(\"hypertension\")\n",
    "\n",
    "condition_name_hits.append(\"carcinoma\")\n",
    "\n",
    "condition_name_hits.append(\"dermatomyositis\")\n",
    "condition_name_hits.append(\"graves\")\n",
    "condition_name_hits.append([\"hashimoto\", \"thyroiditis\"])\n",
    "\n",
    "#Arthritis\n",
    "condition_name_hits.append([\"reactive\", \"arthritis\"])\n",
    "condition_name_hits.append([\"rheumatoid\", \"arthritis\"])\n",
    "condition_name_hits.append(\"arthritis\")\n",
    "condition_name_hits.append(\"sj√∂gren\")\n",
    "condition_name_hits.append([\"lupus\", \"erythematosus\"])\n",
    "condition_name_hits.append([\"chronic\",\"renal\",\"failure\"])\n",
    "condition_name_hits.append(\"leukemia\")\n",
    "condition_name_hits.append(\"lymphoma\")\n",
    "condition_name_hits.append(\"sarcoma\")\n",
    "i = 0\n",
    "for ind, (name, cid) in diagnosis_names[[\"concept_name\", \"concept_id\"]].iterrows(): \n",
    "    name = name.lower()\n",
    "    for pn in condition_name_hits:\n",
    "        def addit(cid, name, pn):\n",
    "            all_condition_ids.append(cid)\n",
    "            condition_id_fullname_map[cid] = name\n",
    "            condition_id_name_map[cid] = pn\n",
    "            if pn in pn_to_id_map:\n",
    "                pn_to_id_map[pn].add(cid)\n",
    "            else:\n",
    "                pn_to_id_map[pn]= set([cid])\n",
    "        \n",
    "        if isinstance(pn, list) and all([x in name for x in pn]):\n",
    "            if (cid == 192855 and name.startswith(\"cancer in situ\")):\n",
    "                print(\"add is attempted\")\n",
    "            addit(cid,name,\"_\".join(pn))\n",
    "            break\n",
    "        if isinstance(pn, str) and pn in name:\n",
    "            addit(cid,name,pn)\n",
    "            break\n",
    "print(f\"Found {len(all_condition_ids)} condition events\")\n",
    "\n",
    "condition_names = sorted(list(pn_to_id_map.keys()))\n",
    "\n",
    "# ca_to_fullname = dict()\n",
    "# for category,cond_ca in category_to_cond_ca.items():\n",
    "#     concept_ancestor_fullnames = []\n",
    "#     for concept_ancestor_id in cond_ca[1]:\n",
    "#         concept_ancestor_fullname = (diagnosis_names_ca.loc[(diagnosis_names_ca.ancestor_concept_id == concept_ancestor_id),\n",
    "#                                                                 'concept_name'].values[0])\n",
    "#         ca_to_fullname[concept_ancestor_id] = concept_ancestor_fullname\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sets(sets):\n",
    "  \"\"\"Joins multiple sets into a single set.\n",
    "\n",
    "  Args:\n",
    "    *sets: A list of sets to join.\n",
    "\n",
    "  Returns:\n",
    "    A set that contains all of the elements from the given sets.\n",
    "  \"\"\"\n",
    "\n",
    "  joined_set = set()\n",
    "  for s in sets:\n",
    "    joined_set |= s\n",
    "\n",
    "  return joined_set\n",
    "\n",
    "def create_new_condition_categories(p_to_id,id_to_p,cat_name):\n",
    "    '''Uses the concept ancestor table and the conditions within each category to create\n",
    "    a category of new conditions doesn't overlap with prior conditions in category\n",
    "    generated from collecting descendants of concept ancestors'''\n",
    "    #get old condition ids for category\n",
    "    condition_ids = join_sets([p_to_id[condition] for condition in category_to_cond_ca[cat_name][0]])\n",
    "    \n",
    "    #get concept ancestor query for category\n",
    "    concept_ancestor_ids = category_to_cond_ca[cat_name][1]\n",
    "    #look at concept ancestor for ids with all of the concept ancestors\n",
    "    new_condition_ids = set(diagnosis_names_ca.loc[\n",
    "        diagnosis_names_ca['ancestor_concept_id'].isin(concept_ancestor_ids),'concept_id']\n",
    "    )\n",
    "    new_condition_ids = new_condition_ids.difference(condition_ids)\n",
    "    \n",
    "    #update dictionarys\n",
    "    new_cat_name = f\"{cat_name}_new\"\n",
    "    p_to_id[new_cat_name] = new_condition_ids\n",
    "    \n",
    "    for cid in new_condition_ids:\n",
    "        id_to_p[cid] = new_cat_name\n",
    "    \n",
    "    return p_to_id,id_to_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category,_, in category_to_cond_ca.items():\n",
    "    pn_to_id_map,condition_id_name_map = create_new_condition_categories(pn_to_id_map,condition_id_name_map,category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category,cond in category_to_cond_ca.items():\n",
    "    old_codes =  cond[0]\n",
    "    new_codes = category + '_new'\n",
    "    print(category)\n",
    "    total_condition_ids = []\n",
    "    for code in old_codes:\n",
    "        total_condition_ids += pn_to_id_map[code]\n",
    "    print(f\"Original number of queried condition codes: {len(total_condition_ids)}. Concept ancestor search contributed {len(pn_to_id_map[new_codes])} codes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names = sorted([x for x in pn_to_id_map.keys() if x.endswith('_new')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the full condition item table\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        {omop_schema}.{in_name} c\n",
    "\"\"\".format(\n",
    "    in_name=in_name,\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA\n",
    ")\n",
    "final_cohort_raw = db.query(sql)\n",
    "final_cohort_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full condition item table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refactoring todo add some code to rewrite the condition_id_name_map with only the codes that I need\n",
    "condition_id_name_map = {condition_id : name for condition_id,name in condition_id_name_map.items() if name in condition_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the full condition item table\n",
    "person_ids = list(final_cohort_raw.person_id)\n",
    "person_ids = person_ids\n",
    "print(len(person_ids))\n",
    "person_ids_str = \", \".join([f\"'{x}'\" for x in person_ids])\n",
    "all_condition_ids = list(condition_id_name_map.keys())\n",
    "all_condition_ids_str = \", \".join([f\"'{x}'\" for x in all_condition_ids])\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        c.*\n",
    "    from\n",
    "        {omop_schema}.condition_occurrence c\n",
    "    inner join\n",
    "        {omop_schema}.{in_name} u\n",
    "    on\n",
    "        c.person_id = u.person_id\n",
    "\"\"\".format(\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA,\n",
    "    in_name=in_name,\n",
    "    person_id = person_ids_str,\n",
    ")\n",
    "condition_candidates = db.query(sql)\n",
    "condition_candidates.set_index([\"person_id\",\"condition_concept_id\"], inplace=True, drop=False)\n",
    "condition_candidates.sort_index(inplace=True)\n",
    "filtered_condition_candidates=condition_candidates[condition_candidates.condition_concept_id.isin(all_condition_ids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new column for time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for time periods\n",
    "# \n",
    "time_periods = [\n",
    "    (0, 180, \"0_6_months\"),\n",
    "    (180, 365, \"6_months_1_yr\"),\n",
    "    (365, 365 * 2, \"1_2_yr\")\n",
    "]\n",
    "new_columns = []\n",
    "for name in condition_names:\n",
    "    for _, time_period, time_name in time_periods:\n",
    "        column_name = name + time_name\n",
    "        new_columns.append((column_name,name, time_period))\n",
    "    new_columns.append((name+\"_full_condition_name\",name, 365*30))\n",
    "final_cohort = final_cohort_raw.copy()\n",
    "for col_name, _, _ in new_columns:\n",
    "    if \"full_condition_name\" in col_name:\n",
    "        col = {col_name: None}\n",
    "    else:\n",
    "        col = {col_name: False}\n",
    "    final_cohort  = final_cohort.assign(**col)\n",
    "final_cohort  = final_cohort.assign(confounder_found=False)\n",
    "new_column_names = [x for x,_,_ in new_columns] + [\"confounder_found\"]\n",
    "final_cohort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confounder_time_period generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_name_dictionary = {k : [] for k in condition_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cid in all_condition_ids:\n",
    "    condition_id_fullname_map[cid] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "start = datetime.datetime.now()\n",
    "from datetime import timedelta\n",
    "l = len(final_cohort)\n",
    "modified_count = 0\n",
    "for index, row in final_cohort.iterrows():\n",
    "    p = row.person_id\n",
    "    d = row.condition_start_date\n",
    "    conditions = filtered_condition_candidates[filtered_condition_candidates.person_id == p ]\n",
    "    c += 1\n",
    "    if c % 1000 == 0:\n",
    "        print(f\"Time elapsed: {(datetime.datetime.now() - start)}\")\n",
    "        print(f\"Iter: {c} / {l}\")\n",
    "    modified = False\n",
    "    \n",
    "    for start_day, days, postfix in time_periods:\n",
    "        prefix_date = d - timedelta(days=days)\n",
    "\n",
    "        #changing d to be offset by the amount of days so what you have for e.g 0 to 6 months is\n",
    "        # 0 days ago <= period < 180 days ago\n",
    "        # 180 days ago <= period < 365 days ago\n",
    "        # 365 days ago <= period < 365*2 days ago\n",
    "        d = d - timedelta(days=start_day)\n",
    "\n",
    "        mask = (conditions.condition_start_date > prefix_date) & (conditions.condition_start_date <= d)\n",
    "        day_filtered_conditions = conditions.loc[mask]\n",
    "        for _, found_event in day_filtered_conditions.iterrows():\n",
    "            modified = True\n",
    "            found_condition_id = found_event.condition_concept_id\n",
    "            condition_name = condition_id_name_map[found_condition_id]\n",
    "            condition_fullname = condition_id_fullname_map[found_condition_id]\n",
    "            condition_name_dictionary[condition_name].append(condition_fullname)\n",
    "            final_cohort.loc[index, condition_name + postfix] = True\n",
    "            final_cohort.loc[index, condition_name + \"_full_condition_name\"] = condition_fullname\n",
    "            final_cohort.loc[index, \"confounder_found\"] = True\n",
    "    if modified:\n",
    "        modified_count += 1\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"Modified count: {modified_count}\")\n",
    "final_cohort.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_final_name_dictionary = {k : set(v) for k,v in condition_name_dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = pn_to_id_map.keys()\n",
    "features = []\n",
    "for col in feat_cols:\n",
    "    for cohort_col in final_cohort.columns:\n",
    "        if cohort_col.startswith(col):\n",
    "            features.append(cohort_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort[features] = 1*final_cohort[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(final_cohort.confounder_found)\n",
    "\n",
    "cols = final_cohort.columns\n",
    "\n",
    "time_6 = [x for x in cols if \"0_6_months\" in x]\n",
    "time_1yr = [x for x in cols if \"6_months_1_yr\" in x]\n",
    "time_1_2yr = [x for x in cols if \"1_2_yr\" in x]\n",
    "\n",
    "years = {\"first 6 months\": time_6, \"6 months to 1 year\": time_1yr, \"1 to 2 years\": time_1_2yr}\n",
    "\n",
    "for name, period in years.items():\n",
    "    cumulative = np.sum((final_cohort[period]).any(axis='columns'))\n",
    "    print(name, cumulative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "code_to_newcode = defaultdict()\n",
    "#create a dictionary remodifying the names\n",
    "for code in condition_names:\n",
    "    code_to_newcode[code] = '_'.join(code.lower().split()).replace('new','concept_ancestor')\n",
    "\n",
    "#display it\n",
    "code_to_newcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cohort_columns = []\n",
    "for i, x in enumerate(final_cohort.columns):\n",
    "    for code in condition_names:\n",
    "        if x.startswith(code):\n",
    "            x = x.replace(code, code_to_newcode[code])\n",
    "    new_cohort_columns.append(x)\n",
    "\n",
    "new_cohort_columns\n",
    "final_cohort.columns = new_cohort_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort = final_cohort.drop(columns=['level_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort.to_sql(out_name,con=db.engine, if_exists=\"replace\", schema=\"cdm_6871_21\")\n",
    "cmd = f'grant select on table cdm_6871_21.{out_name} to cdm_6871_21'\n",
    "db.execute(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save names (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import pandas as pd\n",
    "# path = r\"condition_log.xlsx\"\n",
    "# writer = pd.ExcelWriter(path)\n",
    "# fullname_to_conditionid = {v:k for k, v in condition_id_fullname_map.items()}\n",
    "# #begin\n",
    "\n",
    "# all_ids = []\n",
    "# all_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#         cat_to_ids = [fullname_to_conditionid[x] for x in cat_to_fullname]\n",
    "#         all_ids += cat_to_ids\n",
    "#         all_names += cat_to_fullname\n",
    "#     else:\n",
    "       \n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#         cat_to_ids = [fullname_to_conditionid[x] for x in cat_to_fullname]\n",
    "#         all_ids += cat_to_ids\n",
    "#         all_names += cat_to_fullname\n",
    "\n",
    "#     data = {\"condition_names\":None,\"condition_ids\":None}\n",
    "\n",
    "#     data[\"condition_names\"] = cat_to_fullname\n",
    "#     data[\"condition_ids\"] = cat_to_ids\n",
    "\n",
    "    \n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     df.to_excel(writer, sheet_name = categorical_name,index=False)\n",
    "# #end\n",
    "\n",
    "# #outer loop\n",
    "# writer.save()\n",
    "# writer.close()\n",
    "\n",
    "# all_df = pd.DataFrame({'condition_names':all_names,'condition_ids':all_ids})\n",
    "# all_df.to_csv(\"condition_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#     else:\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if categorical_name in name]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#     print(categorical_name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize names (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#     else:\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if categorical_name in name]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#     print(categorical_name)\n",
    "#     print(f\"length: {len(cat_to_fullname)}\")\n",
    "#     print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>.\")\n",
    "#     print()\n",
    "#     for fullname in cat_to_fullname:\n",
    "#         print(fullname)\n",
    "#     print(\".<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#     else:\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#     print(categorical_name)\n",
    "#     print(f\"length: {len(cat_to_fullname)}\")\n",
    "#     print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>.\")\n",
    "#     print()\n",
    "#     for fullname in cat_to_fullname:\n",
    "#         print(fullname)\n",
    "#     print(\".<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omop_v2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
