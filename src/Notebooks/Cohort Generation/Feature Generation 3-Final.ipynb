{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generates Condition 2 year history Features\n",
    "\n",
    "Obesity, Morbid obesity\n",
    "\n",
    "Malignancies/cancer\n",
    "\n",
    "Prescription of corticosteroids\n",
    "\n",
    "Transplant  (kidney, liver, pancreas, heart, lung, bone marrow)\n",
    "\n",
    "Autoimmune diseases\n",
    "\n",
    "HIV\n",
    "\n",
    "Hypertension\n",
    "\n",
    "Chronic Kidney disease stage 4 or 5\n",
    "\n",
    "Hemodialysis \n",
    "\n",
    "Diabetes mellitus (with or without any complication)\n",
    "\n",
    "Menopause\n",
    "\n",
    "Incontinence \n",
    "\n",
    "Cancer of urinary tract or gynecologic malignancy (remove these patients)\n",
    "\n",
    "Neurogenic bladder (remove these patients)\n",
    "\n",
    "Spina Bifida (remove these patients)\n",
    "\n",
    "Catheter (remove these patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_name = \"manuscript_covariates_1_final\"\n",
    "out_name = \"manuscript_covariates_2_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import sparse\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import Utils.dbutils as dbutils\n",
    "import Utils.data_utils as data_utils\n",
    "import Generators.CohortGenerator as CohortGenerator\n",
    "import Generators.FeatureGenerator as FeatureGenerator\n",
    "import config\n",
    "local_imports = (\n",
    "    dbutils,\n",
    "    data_utils,\n",
    "    CohortGenerator,\n",
    "    FeatureGenerator,\n",
    "    config\n",
    ")\n",
    "for i in local_imports:\n",
    "    i = importlib.reload(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Name Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## database connection parameters\n",
    "# username = config.PG_USERNAME #we use peer authentication so don't need use vars, but in theory would pass them into config_path\n",
    "# password = config.PG_PASSWORD\n",
    "database_name = config.DB_NAME\n",
    "print(database_name)\n",
    "config_path = 'postgresql://{database_name}'.format(\n",
    "    database_name = database_name\n",
    ")\n",
    "connect_args = {\"host\": '/var/run/postgresql/'} # connect_args to pass to sqlalchemy create_engine function\n",
    "\n",
    "# schemas \n",
    "schema_name = 'eol_test_ncjones' # all created tables will be created using this schema\n",
    "cdm_schema_name = config.OMOP_CDM_SCHEMA # the name of the schema housing your OMOP CDM tables\n",
    "print(f\"cdm schema: {cdm_schema_name}\")\n",
    "# caching\n",
    "reset_schema = False # if true, rebuild all data from scratch\n",
    "\n",
    "# set up database, reset schemas as needed\n",
    "db = dbutils.Database(config_path, schema_name, connect_args, cdm_schema_name)\n",
    "# if reset_schema:\n",
    "#     db.execute(\n",
    "#         'drop schema if exists {} cascade'.format(schema_name)\n",
    "#     )\n",
    "# db.execute(\n",
    "#     'create schema if not exists {}'.format(schema_name)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##### Below is stuff to query adverse events\n",
    "\n",
    "\n",
    "# This is to generate adverse condition events based on condition names\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        c.concept_name as concept_name,\n",
    "        c.concept_id as concept_id,\n",
    "        c.domain_id as domain_id\n",
    "    from\n",
    "        {omop_schema}.concept c\n",
    "    where \n",
    "        c.domain_id = 'Condition' \n",
    "\"\"\".format(\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA,\n",
    ")\n",
    "diagnosis_names = db.query(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_condition_ids = []\n",
    "condition_id_name_map = dict()\n",
    "condition_id_fullname_map = dict()\n",
    "pn_to_id_map = dict()\n",
    "condition_name_hits = []\n",
    "condition_ids = []\n",
    "# Obesity, Morbid obesity\n",
    "condition_name_hits.append([\"morbid\", \"obesity\"])\n",
    "# # Malignancies/cancer\n",
    "condition_name_hits.append(\"cancer\")\n",
    "condition_name_hits.append([\"cancer\", \"urinary\"])\n",
    "\n",
    "condition_name_hits.append([\"leukemia\"])\n",
    "\n",
    "condition_name_hits.append(\"malignan\")\n",
    "\n",
    "condition_name_hits.append([\"malignan\",\"gynecologic\"])\n",
    "# Prescription of corticosteroids\n",
    "condition_name_hits.append(\"corticosteroid\")\n",
    "# Transplant  (kidney, liver, pancreas, heart, lung, bone marrow)\n",
    "condition_name_hits.append(\"transplant\")\n",
    "# Autoimmune diseases- ? diagnosis codes\n",
    "# HIV\n",
    "condition_name_hits.append(\"hiv\")\n",
    "# Chronic Kidney disease stage 4 or 5\n",
    "condition_name_hits.append([\"chronic\", \"kidney\"])\n",
    "# Hemodialysis \n",
    "condition_name_hits.append(\"hemodialysis\")\n",
    "# Diabetes mellitus (with or without any complication)\n",
    "condition_name_hits.append([\"diabetes\", \"mellitus\"])\n",
    "# Cancer of urinary tract or gynecologic malignancy (remove these patients)\n",
    "# Menopause\n",
    "condition_name_hits.append(\"menopause\")\n",
    "# Neurogenic bladder (remove these patients)\n",
    "condition_name_hits.append([\"neurogenic\", \"bladder\"])\n",
    "# Incontinence \n",
    "condition_name_hits.append([\"urinary\", \"incontinence\"])\n",
    "# Spina Bifida (remove these patients)\n",
    "condition_name_hits.append([\"spina\", \"pifida\"])\n",
    "# Catheter (remove these patients)\n",
    "condition_name_hits.append(\"catheter\"),\n",
    "condition_name_hits.append(\"hypertension\")\n",
    "# Addison disease\n",
    "condition_name_hits.append(\"addison\")\n",
    "condition_name_hits.append(\"carcinoma\")\n",
    "condition_name_hits.append([\"spina\", \"bifida\"])\n",
    "condition_name_hits.append(\"celiac\")\n",
    "condition_name_hits.append(\"dermatomyositis\")\n",
    "condition_name_hits.append(\"graves\")\n",
    "condition_name_hits.append([\"hashimoto\", \"thyroiditis\"])\n",
    "condition_name_hits.append(\"sclerosis\")\n",
    "condition_name_hits.append([\"myasthenia\", \"gravis\"])\n",
    "condition_name_hits.append([\"pernicious\", \"anemia\"])\n",
    "condition_name_hits.append([\"reactive\", \"arthritis\"])\n",
    "condition_name_hits.append([\"rheumatoid\", \"arthritis\"])\n",
    "condition_name_hits.append(\"arthritis\")\n",
    "condition_name_hits.append(\"sj√∂gren\")\n",
    "condition_name_hits.append([\"lupus\", \"erythematosus\"])\n",
    "condition_name_hits.append([\"chronic\",\"renal\",\"failure\"])\n",
    "condition_name_hits.append(\"leukemia\")\n",
    "condition_name_hits.append(\"lymphoma\")\n",
    "condition_name_hits.append(\"sarcoma\")\n",
    "i = 0\n",
    "for ind, (name, cid) in diagnosis_names[[\"concept_name\", \"concept_id\"]].iterrows(): \n",
    "    name = name.lower()\n",
    "    for pn in condition_name_hits:\n",
    "        def addit(cid, name, pn):\n",
    "            all_condition_ids.append(cid)\n",
    "            condition_id_fullname_map[cid] = name\n",
    "            condition_id_name_map[cid] = pn\n",
    "            if pn in pn_to_id_map:\n",
    "                pn_to_id_map[pn].add(cid)\n",
    "            else:\n",
    "                pn_to_id_map[pn]= set([cid])\n",
    "        \n",
    "\n",
    "        if isinstance(pn, list) and all([x in name for x in pn]):\n",
    "            if (cid == 192855 and name.startswith(\"cancer in situ\")):\n",
    "                print(\"add is attempted\")\n",
    "            addit(cid,name,\"_\".join(pn))\n",
    "            break\n",
    "        if isinstance(pn, str) and pn in name:\n",
    "            addit(cid,name,pn)\n",
    "            break\n",
    "print(f\"Found {len(all_condition_ids)} condition events\")\n",
    "\n",
    "condition_names = sorted(list(pn_to_id_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_dictionary = {k : [len(v)] for k,v in pn_to_id_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the cohort table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the full condition item table\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        {omop_schema}.{in_name} c\n",
    "\"\"\".format(\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA,\n",
    "    in_name=in_name\n",
    ")\n",
    "final_cohort_raw = db.query(sql)\n",
    "final_cohort_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full condition item table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the full condition item table\n",
    "person_ids = list(final_cohort_raw.person_id)\n",
    "person_ids = person_ids\n",
    "print(len(person_ids))\n",
    "person_ids_str = \", \".join([f\"'{x}'\" for x in person_ids])\n",
    "all_condition_ids = list(condition_id_name_map.keys())\n",
    "all_condition_ids_str = \", \".join([f\"'{x}'\" for x in all_condition_ids])\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "    select\n",
    "        c.*\n",
    "    from\n",
    "        {omop_schema}.condition_occurrence c\n",
    "    inner join\n",
    "        {omop_schema}.{in_name} u\n",
    "    on\n",
    "        c.person_id = u.person_id\n",
    "\"\"\".format(\n",
    "    omop_schema=config.OMOP_CDM_SCHEMA,\n",
    "    in_name=in_name,\n",
    "    person_id = person_ids_str,\n",
    ")\n",
    "condition_candidates = db.query(sql)\n",
    "condition_candidates.set_index([\"person_id\",\"condition_concept_id\"], inplace=True, drop=False)\n",
    "condition_candidates.sort_index(inplace=True)\n",
    "filtered_condition_candidates=condition_candidates[condition_candidates.condition_concept_id.isin(all_condition_ids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new column for time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns for time periods\n",
    "# \n",
    "time_periods = [\n",
    "    (0, 180, \"0_6_months\"),\n",
    "    (180, 365, \"6_months_1_yr\"),\n",
    "    (365, 365 * 2, \"1_2_yr\")\n",
    "]\n",
    "new_columns = []\n",
    "for name in condition_names:\n",
    "    for _, time_period, time_name in time_periods:\n",
    "        column_name = name + time_name\n",
    "        new_columns.append((column_name,name, time_period))\n",
    "    new_columns.append((name+\"_full_condition_name\",name, 365*30))\n",
    "final_cohort = final_cohort_raw.copy()\n",
    "for col_name, _, _ in new_columns:\n",
    "    if \"full_condition_name\" in col_name:\n",
    "        col = {col_name: None}\n",
    "    else:\n",
    "        col = {col_name: False}\n",
    "    final_cohort  = final_cohort.assign(**col)\n",
    "final_cohort  = final_cohort.assign(confounder_found=False)\n",
    "new_column_names = [x for x,_,_ in new_columns] + [\"confounder_found\"]\n",
    "final_cohort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confounder_time_period generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_name_dictionary = {k : [] for k,v in condition_dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "c = 0\n",
    "start = datetime.datetime.now()\n",
    "from datetime import timedelta\n",
    "l = len(final_cohort)\n",
    "modified_count = 0\n",
    "for index, row in final_cohort.iterrows():\n",
    "    p = row.person_id\n",
    "    d = row.condition_start_date\n",
    "    conditions = filtered_condition_candidates[filtered_condition_candidates.person_id == p ]\n",
    "    c += 1\n",
    "    if c % 1000 == 0:\n",
    "        print(f\"Time elapsed: {(datetime.datetime.now() - start)}\")\n",
    "        print(f\"Iter: {c} / {l}\")\n",
    "    modified = False\n",
    "    \n",
    "    for start_day, days, postfix in time_periods:\n",
    "        prefix_date = d - timedelta(days=days)\n",
    "\n",
    "        #changing d to be offset by the amount of days so what you have for e.g 0 to 6 months is\n",
    "        # 0 days ago <= period < 180 days ago\n",
    "        # 180 days ago <= period < 365 days ago\n",
    "        # 365 days ago <= period < 365*2 days ago\n",
    "        d = d - timedelta(days=start_day)\n",
    "\n",
    "        mask = (conditions.condition_start_date > prefix_date) & (conditions.condition_start_date <= d)\n",
    "        day_filtered_conditions = conditions.loc[mask]\n",
    "        for _, found_event in day_filtered_conditions.iterrows():\n",
    "            modified = True\n",
    "            found_condition_id = found_event.condition_concept_id\n",
    "            condition_name = condition_id_name_map[found_condition_id]\n",
    "            condition_fullname = condition_id_fullname_map[found_condition_id]\n",
    "            condition_name_dictionary[condition_name].append(condition_fullname)\n",
    "            final_cohort.loc[index, condition_name + postfix] = True\n",
    "            final_cohort.loc[index, condition_name + \"_full_condition_name\"] = condition_fullname\n",
    "            final_cohort.loc[index, \"confounder_found\"] = True\n",
    "\n",
    "    if modified:\n",
    "        modified_count += 1\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"Modified count: {modified_count}\")\n",
    "final_cohort.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add menopause complete history variable (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menopause_candidates =condition_candidates[condition_candidates.condition_concept_id.isin(pn_to_id_map['menopause'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menopause_cohort = final_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "c = 0\n",
    "start = datetime.datetime.now()\n",
    "from datetime import timedelta\n",
    "l = len(final_cohort)\n",
    "modified_count = 0\n",
    "for index, row in menopause_cohort.iterrows():\n",
    "    p = row.person_id\n",
    "    d = row.condition_start_date\n",
    "    conditions = menopause_candidates[menopause_candidates.person_id == p ]\n",
    "    c += 1\n",
    "    if c % 1000 == 0:\n",
    "        print(f\"Time elapsed: {(datetime.datetime.now() - start)}\")\n",
    "        print(f\"Iter: {c} / {l}\")\n",
    "    modified = False\n",
    "    \n",
    "    for start_day, days, postfix in time_periods:\n",
    "\n",
    "        mask = (conditions.condition_start_date <= d)\n",
    "        day_filtered_conditions = conditions.loc[mask]\n",
    "        for _, found_event in day_filtered_conditions.iterrows():\n",
    "            modified = True\n",
    "            found_condition_id = found_event.condition_concept_id\n",
    "            condition_name = condition_id_name_map[found_condition_id]\n",
    "            condition_fullname = condition_id_fullname_map[found_condition_id]\n",
    "            condition_name_dictionary[condition_name].append(condition_fullname)\n",
    "            menopause_cohort.loc[index, condition_name + '_any'] = True\n",
    "            menopause_cohort.loc[index, \"confounder_found\"] = True\n",
    "\n",
    "    if modified:\n",
    "        modified_count += 1\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"Modified count: {modified_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort = menopause_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = pn_to_id_map.keys()\n",
    "features = []\n",
    "for col in feat_cols:\n",
    "    for cohort_col in final_cohort.columns:\n",
    "        if cohort_col.startswith(col):\n",
    "            features.append(cohort_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort[features] = 1*final_cohort[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(final_cohort.confounder_found)\n",
    "\n",
    "cols = final_cohort.columns\n",
    "\n",
    "time_6 = [x for x in cols if \"0_6_months\" in x]\n",
    "time_1yr = [x for x in cols if \"6_months_1_yr\" in x]\n",
    "time_1_2yr = [x for x in cols if \"1_2_yr\" in x]\n",
    "\n",
    "years = {\"first 6 months\": time_6, \"6 months to 1 year\": time_1yr, \"1 to 2 years\": time_1_2yr}\n",
    "\n",
    "for name, period in years.items():\n",
    "    cumulative = np.sum((final_cohort[period]).any(axis='columns'))\n",
    "    print(name, cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort = final_cohort.drop(columns=['level_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort.to_sql(out_name,con=db.engine, if_exists=\"replace\", schema=\"cdm_6871_21\")\n",
    "cmd = 'grant select on table cdm_6871_21.{out_name} to cdm_6871_21'.format(out_name=out_name)\n",
    "db.execute(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save names (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import pandas as pd\n",
    "# path = r\"condition_log.xlsx\"\n",
    "# writer = pd.ExcelWriter(path)\n",
    "# fullname_to_conditionid = {v:k for k, v in condition_id_fullname_map.items()}\n",
    "# #begin\n",
    "\n",
    "# all_ids = []\n",
    "# all_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#         cat_to_ids = [fullname_to_conditionid[x] for x in cat_to_fullname]\n",
    "#         all_ids += cat_to_ids\n",
    "#         all_names += cat_to_fullname\n",
    "#     else:\n",
    "       \n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#         cat_to_ids = [fullname_to_conditionid[x] for x in cat_to_fullname]\n",
    "#         all_ids += cat_to_ids\n",
    "#         all_names += cat_to_fullname\n",
    "\n",
    "#     data = {\"condition_names\":None,\"condition_ids\":None}\n",
    "\n",
    "#     data[\"condition_names\"] = cat_to_fullname\n",
    "#     data[\"condition_ids\"] = cat_to_ids\n",
    "\n",
    "    \n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     df.to_excel(writer, sheet_name = categorical_name,index=False)\n",
    "# #end\n",
    "\n",
    "# #outer loop\n",
    "# writer.save()\n",
    "# writer.close()\n",
    "\n",
    "# all_df = pd.DataFrame({'condition_names':all_names,'condition_ids':all_ids})\n",
    "# all_df.to_csv(\"condition_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#     else:\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if categorical_name in name]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#     print(categorical_name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize names (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#     else:\n",
    "#         cat_to_ids = [name for name in list(condition_id_fullname_map.keys()) if categorical_name in name]\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#     print(categorical_name)\n",
    "#     print(f\"length: {len(cat_to_fullname)}\")\n",
    "#     print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>.\")\n",
    "#     print()\n",
    "#     for fullname in cat_to_fullname:\n",
    "#         print(fullname)\n",
    "#     print(\".<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_names = []\n",
    "# for categorical_name in condition_names:\n",
    "#     if '_' in categorical_name:\n",
    "#         categorical_names = categorical_name.split(\"_\")\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if all(list(map(lambda x: x in name, categorical_names)))]\n",
    "#     else:\n",
    "#         cat_to_fullname = [name for name in list(condition_id_fullname_map.values()) if categorical_name in name]\n",
    "#     print(categorical_name)\n",
    "#     print(f\"length: {len(cat_to_fullname)}\")\n",
    "#     print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>.\")\n",
    "#     print()\n",
    "#     for fullname in cat_to_fullname:\n",
    "#         print(fullname)\n",
    "#     print(\".<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omop_v2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
